{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Información del curso-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figuras/logo_ciencia_datos.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:2em;color:#2467C0\"> Pandas -Parte 7  </h1></center>\n",
    "\n",
    "<center><h2 style=\"font-size:2em;color:#840700\">  Agrupando datos  </h4></center>\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "<col width=\"550\">\n",
    "<col width=\"450\">\n",
    "<tr>\n",
    "<td><img src=\"figuras/agrupando.png\" align=\"left\" style=\"width:500px\"/></td>\n",
    "<td>\n",
    "\n",
    "* **Wes McKinney**, empezó a desarrollar Pandas en el año 2008 mientras trabajaba en *AQR Capital* [https://www.aqr.com/] por la necesidad que tenía de una herramienta flexible de alto rendimiento para realizar análisis cuantitativos en datos financieros. \n",
    "* Antes de dejar AQR convenció a la administración de la empresa de distribuir esta biblioteca bajo licencia de código abierto.\n",
    "* **Pandas** es un acrónimo de **PANel DAta analysiS**\n",
    "   \n",
    "    \n",
    "<br>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías\n",
    "\n",
    "Cargando las bibliotecas que necesitamos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos utilizados en esta Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo *planetas.csv* contiene datos sobre planetas que se han descubierto orbitando estrellas fuera de nuestro sistema solar. En este archivo, cada fila corresponde a un exoplaneta descubierto. Los atributos de cada exoplaneta (y por lo tanto las columnas del archivo) son:\n",
    "\n",
    "* **método**  el método utilizado para descubrir el planeta.\n",
    "* **número** el número total de planetas descubiertos orbitando la estrella anfitriona de este exoplaneta.\n",
    "* **orbital_period** el período del planeta, su \"año\".\n",
    "* **masa** la masa del exoplaneta.\n",
    "* **distancia** la distancia de la estrella anfitriona del exoplaneta a la Tierra en años luz.\n",
    "* **año** el año en que se descubrió el planeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas = pd.read_csv(\"datos/planets.csv\")\n",
    "df_planetas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numero total de filas y columnas\n",
    "df_planetas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caracteristicas de cada columna\n",
    "df_planetas.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar existen columnas que no tienen todos los datos (ver el parametro **count** que es diferente, solo cuenta cuando existe el dato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menudo se require agrupar a través de alguna etiqueta en los *DataFrtames*: esto se implementa en la operación denominada ``groupby``. El nombre \"group by\" o \"agrupar por\"  proviene de un comando en el lenguaje de la base de datos **SQL**, pero quizás sea más esclarecedor pensar en los términos acuñados por primera vez por Hadley Wickham: dividir, aplicar, combinar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta figura se ilustra un ejemplo canónico de esta operación *dividir-aplicar-combinar (split-apply-combine)*, donde \"aplicar\" es una *agregación de suma*:\n",
    "\n",
    "<img align=\"left\" width=\"550\"  float= \"none\" align=\"middle\" src=\"figuras/groupby.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto deja en claro lo que logra ``groupby``:\n",
    "\n",
    "- El paso *split* o *dividir*, implica dividir y agrupar un *DataFrame* según la etiqueta especificada.\n",
    "- El paso *apply* o *aplicar*, implica calcular alguna función, generalmente un agregado, transformación o filtrado, dentro de los grupos individuales.\n",
    "- El paso  *combine* o *combinar*, fusiona los resultados de estas operaciones en un arreglo de salida.\n",
    "\n",
    "Si bien esto ciertamente se podría hacer manualmente usando alguna combinación de los comandos de enmascaramiento, agregación y concatenación cubiertos en las lecciones anteriores, el poder de ``groupby`` es que abstrae estos pasos: el usuario no necesita pensar en *cómo* se realiza el cálculo, sino que piensa en la *operación como un todo*.\n",
    "\n",
    "Como ejemplo concreto, echemos un vistazo al uso de **Pandas** para el cálculo que se muestra en este diagrama.\n",
    "Comenzaremos creando el  *DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6)}, columns=['key', 'data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La operación más básica de dividir-aplicar-combinar se puede calcular con el método ``groupby``, pasando el nombre de la columna de etiqueta deseada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que lo que se retorna no es un conjunto de *DataFrames*, sino un objeto ``DataFrameGroupBy``. Este objeto es donde está la magia: puede pensar en él como una vista especial del DataFrame, que está preparado para profundizar en los grupos, pero no realiza ningún cálculo real hasta que se aplica la agregación. Este enfoque de \"evaluación perezosa\" significa que los agregados comunes se pueden implementar de manera muy eficiente de una manera casi transparente para el usuario.\n",
    "\n",
    "Para producir un resultado, podemos aplicar un agregado a este objeto ``DataFrameGroupBy``, que realizará los pasos apropiados de aplicación/combinación para producir el resultado deseado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sumando los elementos de las etiquetas que coinciden\n",
    "df.groupby('key').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método ``sum()``  es solo una posibilidad aquí; puede aplicar virtualmente cualquier función de agregación Pandas o NumPy común, así como virtualmente cualquier operación válida de *DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El elemento mayor \n",
    "df.groupby('key').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El objeto GroupBy\n",
    "\n",
    "El objeto ``GroupBy`` es una abstracción muy flexible. En muchos sentidos, puede simplemente tratarlo como si fuera una colección de *DataFrames* y hace las cosas difíciles sin que se percate de las operaciones y cálculos realizados. Veamos algunos ejemplos usando los datos de exoplanetas.\n",
    "\n",
    "Quizás las operaciones más importantes que ofrece un ``GroupBy`` son el *agregado*, *filtrado*, *transformación* y *aplicación de un función*.\n",
    "\n",
    "Discutiremos cada uno de estos con más detalle en las siguientes subsecciones, pero antes de eso, vamos a presentar algunas de las otras funciones que se pueden usar con la operación básica de ``GroupBy``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexación de columnas\n",
    "\n",
    "El objeto ``GroupBy`` admite la indexación de columnas de la misma manera que el *DataFrame* y devuelve un objeto ``GroupBy`` modificado.\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('method') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('method')['orbital_period'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí hemos seleccionado un grupo en particular del grupo *DataFrame* original por referencia a su nombre de columna. Al igual que con el objeto ``GroupBy``, no se realiza ningún cálculo hasta que llamamos a algún agregado en el objeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('method')['orbital_period'].median()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si requerimos la lista ordenada alfabéticamente requerimos utilizar la función ``reset_index()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('method')['orbital_period'].median().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es posible aplicar el orden a la columna \"orbital_period\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('method')['orbital_period'].median().reset_index().sort_values('orbital_period', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto da una idea de la escala general de períodos orbitales (en días) a los que es sensible cada método. Podemos hacer lo mismo agrupando con lo el año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('year')['distance'].median() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperarse se descubren planetas mas lejanos conforme va mejorando la tecnología a través de los años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el propósito de las siguientes subsecciones, usaremos este *DataFrame*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data1': range(6),\n",
    "                   'data2': rng.randint(0, 10, 6)},\n",
    "                   columns = ['key', 'data1', 'data2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)  ``aggregate()`` - agregación\n",
    "\n",
    "\n",
    "Puede tomar una cadena, una función o una lista de las mismas y calcular todos los agregados a la vez (puede hacer uso de las funciones de Numpy). Aquí hay un ejemplo rápido que combina todos estos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate([min, np.median, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro patrón útil es pasar un diccionario de nombres de columna de mapeo a operaciones que se aplicarán en esa columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate({'data1': 'min',\n",
    "                             'data2': 'max'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando la operación similar a los datos de los exoplanetas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupando por año y mostrando el \"min\", \"median\" y \"max\" en cada una de las otros parámetros cuantitativos (numéricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('year').aggregate([min, np.median, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos fijamos ahora en la columna de “year” y en las variaciones de los valores de la columna “mass”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('year')['mass'].aggregate([min, np.median, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ordenar los datos de la columna \"median\" de mayor a menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planetas.groupby('year')['mass'].aggregate([np.min, np.median, np.max]).sort_values('median',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) ``filter()`` -  Filtración\n",
    "\n",
    "Una operación de filtrado le permite eliminar datos en función de las propiedades del grupo.\n",
    "Por ejemplo, podríamos querer mantener todos los grupos en los que la desviación estándar es menor que algún valor crítico:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    print(\"x\",x,\",  x['data2'].std()\", x['data2'].std() )\n",
    "    return x['data2'].std() < 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').filter(filter_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función ``filter()`` debe devolver un valor booleano que especifique si el grupo pasa el filtrado. Aquí, debido a que el grupo B y C no tienen una desviación estándar menor que 4, se elimina el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)  apply ()  - Aplicación\n",
    "\n",
    "El método  ``apply()`` le permite aplicar una función arbitraria a los resultados del grupo.\n",
    "La función debe tomar un *DataFrame* y devolver un objeto Pandas  o un escalar; la operación de combinación se adaptará al tipo de salida devuelta.\n",
    "\n",
    "Por ejemplo, aquí hay una \"aplicación\" que normaliza la primera columna por la suma de la segunda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_by_data2(x):\n",
    "    #print(\"x['data2'].sum() )\n",
    "    x['data1'] /= x['data2'].sum()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key')['data2'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los elementos de data1-subgrupoA se dividirán entre 8\n",
    "# Todos los elementos de data1-subgrupoB se dividirán entre 7\n",
    "# Todos los elementos de data1-subgrupoC se dividirán entre 12\n",
    "df.groupby('key').apply(norm_by_data2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
